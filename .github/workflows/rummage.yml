name: Daily Palia Rummage Post

on:
  schedule:
    - cron: "0 13 * * *"
  workflow_dispatch:

jobs:
  post:
    runs-on: ubuntu-latest
    steps:
      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install requests pillow playwright
          python -m playwright install --with-deps chromium

      - name: Render maps + extract grid + post to Discord
        env:
          WEBHOOK: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          python - <<'EOF'
          import os, io, json, re
          import requests
          from datetime import datetime
          from PIL import Image
          from playwright.sync_api import sync_playwright

          webhook = os.environ.get("WEBHOOK")
          if not webhook:
              raise SystemExit("Missing DISCORD_WEBHOOK_URL secret.")

          maps = [
              ("ðŸŒ¿ Kilima Valley", "https://palia.th.gl/rummage-pile?map=kilima-valley"),
              ("ðŸŒŠ Bahari Bay", "https://palia.th.gl/rummage-pile?map=bahari-bay"),
              ("ðŸŒ² Elderwood", "https://palia.th.gl/rummage-pile?map=elderwood"),
          ]

          GRID_RE = re.compile(r"\b([A-Z])\s?([1-9]|1[0-9])\b")  # A1..Z19 (covers C6 etc.)

          def best_grid_from_text(text: str):
              # Prefer letter+number like C6; return first match
              m = GRID_RE.search(text)
              if not m:
                  return None
              return f"{m.group(1)}{m.group(2)}"

          screenshots = []
          grid_results = {}

          with sync_playwright() as p:
              browser = p.chromium.launch()
              context = browser.new_context(viewport={"width": 1280, "height": 720})
              page = context.new_page()

              for name, url in maps:
                  # collect grids observed while loading this specific map
                  seen_grids = []

                  def on_response(resp):
                      try:
                          ct = (resp.headers.get("content-type") or "").lower()
                          if "application/json" not in ct:
                              return
                          # Only inspect responses from th.gl domains
                          if "th.gl" not in resp.url:
                              return
                          data = resp.json()
                          blob = json.dumps(data, ensure_ascii=False)
                          g = best_grid_from_text(blob)
                          if g:
                              seen_grids.append(g)
                      except Exception:
                          pass

                  page.on("response", on_response)

                  page.goto(url, wait_until="networkidle", timeout=60000)
                  page.wait_for_timeout(4000)  # let late fetches finish

                  # Pick the most common grid code we saw (reduces random false positives)
                  if seen_grids:
                      # count frequency
                      freq = {}
                      for g in seen_grids:
                          freq[g] = freq.get(g, 0) + 1
                      grid = sorted(freq.items(), key=lambda x: (-x[1], x[0]))[0][0]
                  else:
                      grid = None

                  grid_results[name] = grid

                  # Screenshot
                  png_bytes = page.screenshot(full_page=False)
                  img = Image.open(io.BytesIO(png_bytes)).convert("RGB")
                  w, h = img.size
                  crop_top = 110
                  img = img.crop((0, crop_top, w, h))
                  screenshots.append(img)

                  # remove listener so the next map doesn't inherit previous handlers
                  page.remove_listener("response", on_response)

              browser.close()

          # Create vertical collage image
          collage_w = max(im.size[0] for im in screenshots)
          collage_h = sum(im.size[1] for im in screenshots)
          collage = Image.new("RGB", (collage_w, collage_h), (255, 255, 255))
          y = 0
          for im in screenshots:
              collage.paste(im, (0, y))
              y += im.size[1]

          out = io.BytesIO()
          collage.save(out, format="PNG", optimize=True)
          out.seek(0)

          # Build embed fields with grid text
          fields = []
          for name, url in maps:
              grid = grid_results.get(name)
              if grid:
                  value = f"**Loot pile:** `{grid}`\n[Open map]({url})"
              else:
                  value = f"**Loot pile:** `(grid not detected)`\n[Open map]({url})"
              fields.append({"name": name, "value": value, "inline": False})

          embed = {
              "title": "ðŸ—“ï¸ Today's Rummage Piles",
              "description": "Map + grid callouts (3 maps).",
              "fields": fields,
              "image": {"url": "attachment://rummage.png"},
              "footer": {"text": "Source: palia.th.gl"},
              "timestamp": datetime.utcnow().isoformat()
          }

          payload_json = {"username": "Palia Rummage Tracker", "embeds": [embed]}
          files = {
              "payload_json": (None, json.dumps(payload_json), "application/json"),
              "files[0]": ("rummage.png", out, "image/png"),
          }

          resp = requests.post(webhook, files=files, timeout=60)
          print("Discord status:", resp.status_code)
          print(resp.text[:500])
          resp.raise_for_status()
          EOF
