name: Daily Palia Rummage Post

on:
  schedule:
    - cron: "0 6 * * *"   # 1:00am EST = 06:00 UTC (becomes 2:00am EDT)
  workflow_dispatch:

jobs:
  post:
    runs-on: ubuntu-latest
    steps:
      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install requests pillow playwright
          python -m playwright install --with-deps chromium

      - name: Screenshot full grid maps + post to Discord
        env:
          WEBHOOK: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          python - <<'EOF'
          import os, io, json
          import requests
          from datetime import datetime
          from PIL import Image, ImageDraw
          from playwright.sync_api import sync_playwright

          webhook = os.environ.get("WEBHOOK")
          if not webhook:
              raise SystemExit("Missing DISCORD_WEBHOOK_URL secret.")

          maps = [
              ("üåø Kilima Valley", "https://palia.th.gl/rummage-pile?map=kilima-valley"),
              ("üåä Bahari Bay", "https://palia.th.gl/rummage-pile?map=bahari-bay"),
              ("üå≤ Elderwood", "https://palia.th.gl/rummage-pile?map=elderwood"),
          ]

          # Candidate selectors for the map/grid container (we‚Äôll try in order)
          MAP_SELECTORS = [
              "canvas",                 # some maps render to canvas
              "svg",                    # sometimes grid overlays are svg
              '[class*="map" i]',       # generic map container
              '[id*="map" i]',          # generic map id
              "main",                   # fallback: main content area
          ]

          screenshots = []
          failures = []  # keep track of maps that fail to render

          with sync_playwright() as p:
              browser = p.chromium.launch()
              context = browser.new_context(viewport={"width": 1100, "height": 700})
              page = context.new_page()

              for name, url in maps:
                  try:
                      page.goto(url, wait_until="networkidle", timeout=60000)
                      page.wait_for_timeout(2500)

                      # Find a good element to screenshot
                      target = None
                      for sel in MAP_SELECTORS:
                          loc = page.locator(sel).first
                          try:
                              if loc.count() > 0:
                                  box = loc.bounding_box()
                                  if box and box["width"] > 400 and box["height"] > 250:
                                      target = loc
                                      break
                          except Exception:
                              pass

                      if target is None:
                          # Absolute fallback: full viewport screenshot
                          png_bytes = page.screenshot(full_page=False)
                      else:
                          # Element screenshot = cleanest full-grid capture
                          png_bytes = target.screenshot()

                      img = Image.open(io.BytesIO(png_bytes)).convert("RGB")

                      # Optional polish: subtle border
                      draw = ImageDraw.Draw(img)
                      draw.rectangle(
                          [0, 0, img.size[0] - 1, img.size[1] - 1],
                          outline=(200, 200, 200)
                      )

                      screenshots.append(img)

                  except Exception as e:
                      failures.append((name, str(e)))
                      print(f"[WARN] Failed to capture {name}: {e}")

              browser.close()

          # If *everything* failed, stop with a clear error
          if not screenshots:
              raise SystemExit("All map screenshots failed. Check site availability or selectors.")

          # Build vertical collage
          collage_w = max(im.size[0] for im in screenshots)
          collage_h = sum(im.size[1] for im in screenshots)
          collage = Image.new("RGB", (collage_w, collage_h), (255, 255, 255))

          y = 0
          for im in screenshots:
              # center each image in case widths differ
              x = (collage_w - im.size[0]) // 2
              collage.paste(im, (x, y))
              y += im.size[1]

          out = io.BytesIO()
          collage.save(out, format="PNG", optimize=True)
          out.seek(0)

          # Build embed fields (always include links)
          fields = []
          for name, url in maps:
              fields.append({
                  "name": name,
                  "value": f"[Open today‚Äôs rummage map]({url})",
                  "inline": False
              })

          desc = "Daily full-grid screenshots (3 maps)."
          if failures:
              # Keep this short so it doesn‚Äôt look scary; it‚Äôs just informative
              failed_names = ", ".join([f[0] for f in failures])
              desc += f"\n‚ö†Ô∏è Note: screenshot issue for {failed_names} (link still included)."

          embed = {
              "title": "üóìÔ∏è Today's Rummage Piles",
              "description": desc,
              "fields": fields,
              "image": {"url": "attachment://rummage.png"},
              "footer": {"text": "Source: palia.th.gl"},
              "timestamp": datetime.utcnow().isoformat()
          }

          payload_json = {"username": "Palia Rummage Tracker", "embeds": [embed]}

          files = {
              "payload_json": (None, json.dumps(payload_json), "application/json"),
              "files[0]": ("rummage.png", out, "image/png"),
          }

          resp = requests.post(webhook, files=files, timeout=60)
          print("Discord status:", resp.status_code)
          print(resp.text[:500])
          resp.raise_for_status()
          EOF
